{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a4b2e0c-1c05-4483-975e-664035042b41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-05 18:48:47.099246: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-09-05 18:48:47.099285: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from types import SimpleNamespace\n",
    "import tensorflow as tf\n",
    "\n",
    "import wandb\n",
    "\n",
    "from data_loader import DataLoader\n",
    "from utils.callbacks import TensorBoard\n",
    "from utils.util import *\n",
    "from utils.args_loader import load_model_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b449bbd-72d0-43b2-b093-a3634925bdc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = Path(\"/mnt/disks/KITTI/small/\")\n",
    "data_path.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "238c50eb-8366-410d-ab91-caa82d62c9b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-05 18:48:49.155193: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-05 18:48:49.156015: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-09-05 18:48:49.156096: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2022-09-05 18:48:49.156165: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2022-09-05 18:48:49.156234: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2022-09-05 18:48:49.156325: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2022-09-05 18:48:49.156389: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2022-09-05 18:48:49.156452: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2022-09-05 18:48:49.156537: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2022-09-05 18:48:49.156550: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-09-05 18:48:49.157089: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "arg = SimpleNamespace(model=\"squeezesegv2\",\n",
    "                      config=\"squeezesegv2kitti\",\n",
    "                      data_path=data_path,\n",
    "                      train_dir=\"../output\",\n",
    "                      epochs=10)   \n",
    "\n",
    "config, model = load_model_config(arg.model, arg.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d27fef5-b6e8-4f01-9844-1336dd2adba2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TFRecord exists at /mnt/disks/KITTI/small/train.tfrecord. Skipping TFRecord writing.\n",
      "TFRecord exists at /mnt/disks/KITTI/small/val.tfrecord. Skipping TFRecord writing.\n"
     ]
    }
   ],
   "source": [
    "train_dl = DataLoader(\"train\", arg.data_path, config).write_tfrecord_dataset().read_tfrecord_dataset()\n",
    "val_dl = DataLoader(\"val\", arg.data_path, config).write_tfrecord_dataset().read_tfrecord_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d6e6a4-7d94-46a9-85ca-8e0733562149",
   "metadata": {},
   "source": [
    "## Log validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b768c71-e993-4822-ba3b-e0457b6ac191",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize(img, factor=1):\n",
    "    return tf.image.resize(img, [img.shape[0]*factor, img.shape[1]*factor]).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6b18b67d-7a73-4956-b9d0-71907e88b7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _create_row(lidar_input, label, class_color_map):\n",
    "    \"Create tuple of images and points\"\n",
    "    label = label[:, :]\n",
    "    label_image = class_color_map[label.numpy().reshape(-1)].reshape([label.shape[0], label.shape[1], 3])\n",
    "    depth_image = lidar_input.numpy()[:, :, [4]]\n",
    "    intensity = lidar_input.numpy()[:, :, [3]]\n",
    "    points = lidar_input.numpy()[:, :, :3]\n",
    "    points_rgb = np.concatenate([points, (255*label_image).astype(int)], axis=-1).reshape(-1, 6)\n",
    "    \n",
    "    depth_image, label_image, intensity_image  = map(resize, [depth_image, label_image, intensity])\n",
    "    return (wandb.Image(label_image), \n",
    "            wandb.Image(depth_image), \n",
    "            wandb.Image(intensity_image), \n",
    "            wandb.Object3D({\"type\": \"lidar/beta\", \"points\":points_rgb}),\n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "171d8326-a182-45d7-8f09-56c18f1c6f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_input_data(lidar_input, label, class_color_map):\n",
    "    \"Log to media panel\"\n",
    "    label_image, depth_image, intensity_image, points_rgb = _create_row(lidar_input, \n",
    "                                                                        label, s\n",
    "                                                                        class_color_map)\n",
    "    # log 2 wandb\n",
    "    wandb.log({'Images/Label Image': label_image})\n",
    "    wandb.log({'Images/Depth Image': depth_image})\n",
    "    wandb.log({'Images/Intensity Image': intensity_image})\n",
    "    wandb.log({\"Images/3D\": points_rgb})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "47ddfa79-4faa-430c-8cb8-1b25b8c33a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_data = []\n",
    "n=20\n",
    "for i, ((lidar_input, _), label, _) in enumerate(val_dl):\n",
    "    if i < n:\n",
    "        table_data.append(_create_row(lidar_input[0], label[0], model.CLS_COLOR_MAP))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fe5ba85d-1f45-4e8e-afee-0a19828e3312",
   "metadata": {},
   "outputs": [],
   "source": [
    "table = wandb.Table(columns=[\"Label Image\", \"Depth Image\", \"Intensity Image\", \"LiDAR\"],\n",
    "                    data=table_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "25adcf3b-b6a5-4d5c-b8aa-22de4f9a4115",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/tcapelle/wandb/PCLSegmentation/pcl_segmentation/wandb/run-20220905_185625-3vd88xwb</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/av-team/small_kitti/runs/3vd88xwb\" target=\"_blank\">drawn-dragon-18</a></strong> to <a href=\"https://wandb.ai/av-team/small_kitti\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='201.950 MB of 201.951 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.99â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">drawn-dragon-18</strong>: <a href=\"https://wandb.ai/av-team/small_kitti/runs/3vd88xwb\" target=\"_blank\">https://wandb.ai/av-team/small_kitti/runs/3vd88xwb</a><br/>Synced 5 W&B file(s), 1 media file(s), 81 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220905_185625-3vd88xwb/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with wandb.init(project=\"small_kitti\", entity=\"av-team\", job_type=\"log_dataset\"):\n",
    "    wandb.log({\"validation_ds\":table})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ec0846-4251-451f-9642-fae62c6a28eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
