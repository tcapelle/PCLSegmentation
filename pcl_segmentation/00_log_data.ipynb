{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a4b2e0c-1c05-4483-975e-664035042b41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-07 11:03:55.308351: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-09-07 11:03:55.308395: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from types import SimpleNamespace\n",
    "import tensorflow as tf\n",
    "\n",
    "import wandb\n",
    "\n",
    "from data_loader import DataLoader\n",
    "from utils.callbacks import TensorBoard\n",
    "from utils.util import *\n",
    "from utils.args_loader import load_model_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b449bbd-72d0-43b2-b093-a3634925bdc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = Path(\"/mnt/disks/KITTI/small/\")\n",
    "data_path.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "238c50eb-8366-410d-ab91-caa82d62c9b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-07 11:03:57.247875: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-07 11:03:57.248680: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-09-07 11:03:57.248749: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2022-09-07 11:03:57.248816: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2022-09-07 11:03:57.248875: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2022-09-07 11:03:57.248935: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2022-09-07 11:03:57.248993: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2022-09-07 11:03:57.249052: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2022-09-07 11:03:57.249110: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2022-09-07 11:03:57.249121: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-09-07 11:03:57.249562: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "arg = SimpleNamespace(model=\"squeezesegv2\",\n",
    "                      config=\"squeezesegv2kitti\",\n",
    "                      data_path=data_path,\n",
    "                      train_dir=\"../output\",\n",
    "                      epochs=10)   \n",
    "\n",
    "config, model = load_model_config(arg.model, arg.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d27fef5-b6e8-4f01-9844-1336dd2adba2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TFRecord exists at /mnt/disks/KITTI/small/train.tfrecord. Skipping TFRecord writing.\n",
      "TFRecord exists at /mnt/disks/KITTI/small/val.tfrecord. Skipping TFRecord writing.\n"
     ]
    }
   ],
   "source": [
    "train_dl = DataLoader(\"train\", arg.data_path, config).write_tfrecord_dataset().read_tfrecord_dataset()\n",
    "val_dl = DataLoader(\"val\", arg.data_path, config).write_tfrecord_dataset().read_tfrecord_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d6e6a4-7d94-46a9-85ca-8e0733562149",
   "metadata": {},
   "source": [
    "## Log validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b768c71-e993-4822-ba3b-e0457b6ac191",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize(img, factor=1):\n",
    "    return tf.image.resize(img, [img.shape[0]*factor, img.shape[1]*factor]).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b18b67d-7a73-4956-b9d0-71907e88b7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _create_row(lidar_input, label, class_color_map):\n",
    "    \"Create tuple of images and points\"\n",
    "    label_image = class_color_map[label.numpy().reshape(-1)].reshape([label.shape[0], label.shape[1], 3])\n",
    "    depth_image = lidar_input.numpy()[:, :, [4]]\n",
    "    intensity = lidar_input.numpy()[:, :, [3]]\n",
    "    points = lidar_input.numpy()[:, :, :3]\n",
    "    points_rgb = np.concatenate([points, (255*label_image).astype(int)], axis=-1).reshape(-1, 6)\n",
    "    \n",
    "    depth_image, label_image, intensity_image  = map(resize, [depth_image, label_image, intensity])\n",
    "    return (wandb.Image(label_image), \n",
    "            wandb.Image(depth_image), \n",
    "            wandb.Image(intensity_image), \n",
    "            wandb.Object3D({\"type\": \"lidar/beta\", \"points\":points_rgb}),\n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "171d8326-a182-45d7-8f09-56c18f1c6f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_input_data(lidar_input, label, class_color_map, step=None):\n",
    "    \"Log to media panel\"\n",
    "    label_image, depth_image, intensity_image, points_rgb = _create_row(lidar_input, \n",
    "                                                                        label,\n",
    "                                                                        class_color_map)\n",
    "    # log 2 wandb\n",
    "    wandb.log({'Images/Label Image': label_image},step=step)\n",
    "    wandb.log({'Images/Depth Image': depth_image},step=step)\n",
    "    wandb.log({'Images/Intensity Image': intensity_image},step=step)\n",
    "    wandb.log({\"Images/3D\": points_rgb},step=step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3a13cbe4-312a-4836-89db-2cdca2d33a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _create_pred_row(lidar_input, prediction, label, class_color_map):\n",
    "    pred_image = class_color_map[prediction.reshape(-1)].reshape([label.shape[0], label.shape[1], 3])\n",
    "    points = lidar_input.numpy()[...,:3]\n",
    "    points_preds_rgb = np.concatenate([points, (255*pred_image).astype(int)], axis=-1).reshape(-1, 6)\n",
    "    pred_image = resize(pred_image)\n",
    "    return (wandb.Image(pred_image),\n",
    "            wandb.Object3D({\"type\": \"lidar/beta\", \"points\":points_preds_rgb}),\n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3ffe03c3-84be-41fb-b438-264d17da719e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_model_predictions(lidar_input, prediction, label, class_color_map, step=None):\n",
    "    \"Log pred image and points\"\n",
    "    pred_image, points_rgb = _create_pred_row(lidar_input, prediction, label, class_color_map)\n",
    "    wandb.log({'Images/Prediction Image':pred_image},step=step)\n",
    "    wandb.log({\"Images/3D_preds\": points_rgb},step=step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "bc05f0d7-b250-4d86-ad95-3fca2b48f684",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pred_table(lidar_inputs,labels, predictions):\n",
    "    table_data = []\n",
    "    for i, (lidar_input, label, prediction) in enumerate(zip(lidar_inputs,labels, predictions)):\n",
    "        input_row = _create_row(lidar_input, label, model.CLS_COLOR_MAP)\n",
    "        preds_row = _create_pred_row(lidar_input, prediction, label, model.CLS_COLOR_MAP)\n",
    "        table_data.append(input_row+preds_row)\n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8dc305fd-87f8-4819-a9a1-cc2c78da72d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_preds(model, dataset, num_images=5):\n",
    "    # a batch of images\n",
    "    (lidar_inputs, lidar_masks), labels, weights = dataset.take(1).get_single_element() \n",
    "\n",
    "    num_images = min(num_images, lidar_inputs.shape[0])\n",
    "\n",
    "    # select a fixed number of inputs\n",
    "    lidar_inputs = lidar_inputs[:num_images, :, :]\n",
    "    lidar_masks = lidar_masks[:num_images, :, :]\n",
    "    labels = labels[:num_images, :, :]\n",
    "    weights = weights[:num_images, :, :]\n",
    "\n",
    "    # forward pass\n",
    "    probabilities, predictions = model([lidar_inputs, lidar_masks])\n",
    "\n",
    "    return lidar_inputs, predictions.numpy(), labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b7245072-63cd-4604-8432-e29403c46d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lidar_inputs, predictions, labels = compute_preds(model, val_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "47ddfa79-4faa-430c-8cb8-1b25b8c33a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "table = create_pred_table(lidar_inputs,labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6e0adcae-1647-4131-b5d2-8236221867af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<wandb.sdk.data_types.image.Image at 0x7f00e2e68fa0>,\n",
       " <wandb.sdk.data_types.image.Image at 0x7f00e2e57ee0>,\n",
       " <wandb.sdk.data_types.image.Image at 0x7f017c380c40>,\n",
       " <wandb.sdk.data_types.object_3d.Object3D at 0x7f017c380f10>,\n",
       " <wandb.sdk.data_types.image.Image at 0x7f017c381030>,\n",
       " <wandb.sdk.data_types.object_3d.Object3D at 0x7f017c380250>)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fe5ba85d-1f45-4e8e-afee-0a19828e3312",
   "metadata": {},
   "outputs": [],
   "source": [
    "table = wandb.Table(columns=[\"Label Image\", \"Depth Image\", \"Intensity Image\", \"LiDAR\", \"Pred Image\", \"Pred LiDAR\"],\n",
    "                    data=table_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "25adcf3b-b6a5-4d5c-b8aa-22de4f9a4115",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/tcapelle/wandb/PCLSegmentation/pcl_segmentation/wandb/run-20220907_111512-1s6dyz7l</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/av-team/small_kitti/runs/1s6dyz7l\" target=\"_blank\">pious-fire-30</a></strong> to <a href=\"https://wandb.ai/av-team/small_kitti\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='60.370 MB of 60.371 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.9999â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">pious-fire-30</strong>: <a href=\"https://wandb.ai/av-team/small_kitti/runs/1s6dyz7l\" target=\"_blank\">https://wandb.ai/av-team/small_kitti/runs/1s6dyz7l</a><br/>Synced 5 W&B file(s), 1 media file(s), 19 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220907_111512-1s6dyz7l/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with wandb.init(project=\"small_kitti\", entity=\"av-team\", job_type=\"log_preds\"):\n",
    "    wandb.log({\"pred_val\":table})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "23ea49ff-7b67-4587-bc17-e3c30c7cae8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wandb.keras import WandbCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38c7dff-707d-404d-871e-20d2b64e0790",
   "metadata": {},
   "outputs": [],
   "source": [
    "WandbCallback(save_model="
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
